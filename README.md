# ğŸ™‚Moving-Emoji-GenerationğŸ¤¥


## íˆ¬ë¹…í‹°ì½˜ - Image2Video ê¸°ë°˜ ë‚˜ë§Œì˜ ì›€ì§ì´ëŠ” ì´ëª¨í‹°ì½˜ ìƒì„±

íˆ¬ë¹…í‹°ì½˜ì€ GAN based image2video ë°©ë²•ì„ í™œìš©í•œ ë‚˜ë§Œì˜ ì›€ì§ì´ëŠ” ì´ëª¨í‹°ì½˜ ìƒì„±ì„ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

## Notice

EmoGE'T(Emoji GEneratied by Tobigs)ì€ íˆ¬ë¹…ìŠ¤ 8ëª…ì˜ ë©¤ë²„ê°€ ëª¨ì—¬ image2video ê¸°ë°˜ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•œ íŒ€ì…ë‹ˆë‹¤.

íˆ¬ë¹…ìŠ¤ ì œ 11íšŒ ì»¨í¼ëŸ°ìŠ¤ì—ì„œ ì‹œì—°í•œ ì›¹ í˜ì´ì§€ëŠ” [Demo web page]("www.google.com")ì…ë‹ˆë‹¤.


íˆ¬ë¹…í‹°ì½˜ìœ¼ë¡œ ìì‹ ì˜ ì›€ì§ì´ëŠ” ì´ëª¨í‹°ì½˜ì„ ë§Œë“¤ì–´ë³´ì„¸ìš” !
íˆ¬ë¹…í‹°ì½˜ì—ì„œëŠ” ì•„ë˜ì™€ ê°™ì€ ì˜µì…˜ì´ ìˆìŠµë‹ˆë‹¤. 

ì´ëª¨ì§€ ìŠ¤íƒ€ì¼ ì„ íƒ
| Animation  |  Babyface | Painting  | 
|---|---|---|
|  <img src="images/anime.jpg" width="150" height="150"> |  <img src="images/baby.jpeg" width="150" height="150"> |  <img src="images/painting.jpeg" width="150" height="150"> | 


ì´ëª¨ì§€ ê°ì • ì„ íƒ
| Happiness  |  Disgusted | Sadness  | 
|---|---|---|
|  <img src="images/happy.png" width="150" height="150"> |  <img src="images/disgust.png" width="150" height="150"> |  <img src="images/sad.jpg" width="150" height="150"> | 

ìœ„ì˜ ì˜µì…˜ì— ë”°ë¼, í•™ìŠµëœ ëª¨ë¸ì´ ë‚˜ë§Œì˜ ì›€ì§ì´ëŠ” ì´ëª¨í‹°ì½˜ì„ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.


## Requirements

We have tested on:

- CUDA 11.0
- python 3.8.5
- pytorch 1.7.1
- numpy 1.19.2
- opencv-python  4.5.1
- dlib 19.21.1
- scikit-learn 0.24.0
- Pillow 8.1.0
- Ninja 1.10.0
- glob2 0.7

## Usage

### Generate your own Emoji

You can generate your own moving emoticon :)

> python emoticon_generate.py --file ImagePath --transform Animation --emotion Emotion --type OutputType --model Approach

For example,
> python emoticon_generate.py --file 00001.jpg --transform baby --emotion disgusted --type mp4 --model sol1

### Training

Train the landmark generation model using sol1 approach

> python sol1/main.py --data_path DataPath --conditions Conditions

Generate the predicted landmarks using sol1 model

> python so1/generate_videos.py [model path] [image] [class] [save_path]

Train the landmark generation model using sol2 approach

> python sol1/train.py --image_discriminator PatchImageDiscriminator --video_discriminator CategoricalVideoDiscriminator --dim_z_category 3 --video_length 16  

Generate the predicted landmarks using sol2 model

> python so1/generate_videos.py [model path] [image] [class] [save_path]



## Samples

<img src="images/example_3.gif" width="300" height="300"> <img src="images/example_2.gif" width="300" height="300"> <img src="images/example_1.gif" width="300" height="300"> <img src="example_1.gif" width="300" height="300">

## Contributor ğŸŒŸ

| 13ê¸°  |   |   |   |
|---|---|---|---|
| [ì‹ ë¯¼ì •]("[https://google.com](https://github.com/minjung-s)") |  [ì´ìœ ë¯¼]("[https://github.com/yourmean](https://github.com/yourmean)") |  [ì´ì˜ˆì§€]("[https://github.com/simba-pumba](https://github.com/simba-pumba)") |  [ìµœí˜œë¹ˆ]("[https://github.com/lilly9117](https://github.com/lilly9117)") |
|  <img src="images/soonmoo.jpeg" width="150" height="150"> |  <img src="images/soonmoo.jpeg" width="150" height="150"> |  <img src="images/soonmoo.jpeg" width="150" height="150"> |   <img src="images/soonmoo.jpeg" width="150" height="150">|

| 14ê¸°  |   |   |   |
|---|---|---|---|
| [ê¹€ë¯¼ê²½]("[https://github.com/mink7878](https://github.com/mink7878)")  |  [ê¹€ìƒí˜„]("[https://github.com/shkim960520](https://github.com/shkim960520)") |  [ì •ì¬ìœ¤]("[https://github.com/Jeong-JaeYoon](https://github.com/Jeong-JaeYoon)) |  [í•œìœ ì§„]("[https://github.com/Yu-Jin22](https://github.com/Yu-Jin22)") |

|  <img src="images/soonmoo.jpeg" width="150" height="150"> |  <img src="images/soonmoo.jpeg" width="150" height="150"> |  <img src="images/soonmoo.jpeg" width="150" height="150"> |   <img src="images/soonmoo.jpeg" width="150" height="150">|


## Thanks
- íˆ¬ë¹…ìŠ¤ 12ê¸° ê¹€ìˆ˜ì•„ë‹˜
  

## Reference

- [https://github.com/rosinality/stylegan2-pytorch](https://github.com/rosinality/stylegan2-pytorch)
- [https://github.com/PieraRiccio/stylegan2-pytorch](https://github.com/PieraRiccio/stylegan2-pytorch)
- [https://github.com/justinpinkney/toonify](https://github.com/justinpinkney/toonify)
- [https://github.com/marsbroshok/face-replace](https://github.com/marsbroshok/face-replace)
- [https://github.com/sergeytulyakov/mocogan](https://github.com/sergeytulyakov/mocogan) # sol2íŒ€ í™•ì¸ì¢€ìš”
- Yaohui Wang, Piotr Bilinski, Francois Bremond, Antitza Dantcheva. ImaGINator: Conditional Spatio-Temporal GAN for Video Generation. 2019. # sol2íŒ€ í™•ì¸ì¢€ìš”

